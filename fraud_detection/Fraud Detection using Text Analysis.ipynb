{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2090, 6)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('chapter_4/enron_emails_clean.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message-ID</th>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th>Date</th>\n",
       "      <th>content</th>\n",
       "      <th>clean_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;8345058.1075840404046.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>('advdfeedback@investools.com')</td>\n",
       "      <td>('advdfeedback@investools.com')</td>\n",
       "      <td>2002-01-29 23:20:55</td>\n",
       "      <td>INVESTools Advisory\\nA Free Digest of Trusted ...</td>\n",
       "      <td>investools advisory free digest trusted invest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;1512159.1075863666797.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>('richard.sanders@enron.com')</td>\n",
       "      <td>('richard.sanders@enron.com')</td>\n",
       "      <td>2000-09-20 19:07:00</td>\n",
       "      <td>----- Forwarded by Richard B Sanders/HOU/ECT o...</td>\n",
       "      <td>forwarded richard b sanders hou ect pm justin ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;26118676.1075862176383.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>('m..love@enron.com')</td>\n",
       "      <td>('m..love@enron.com')</td>\n",
       "      <td>2001-10-30 16:15:17</td>\n",
       "      <td>hey you are not wearing your target purple shi...</td>\n",
       "      <td>hey wearing target purple shirt today mine wan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;10369289.1075860831062.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>('leslie.milosevich@kp.org')</td>\n",
       "      <td>('leslie.milosevich@kp.org')</td>\n",
       "      <td>2002-01-30 17:54:18</td>\n",
       "      <td>Leslie Milosevich\\n1042 Santa Clara Avenue\\nAl...</td>\n",
       "      <td>leslie milosevich santa clara avenue alameda c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;26728895.1075860815046.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>('rtwait@graphicaljazz.com')</td>\n",
       "      <td>('rtwait@graphicaljazz.com')</td>\n",
       "      <td>2002-01-30 19:36:01</td>\n",
       "      <td>Rini Twait\\n1010 E 5th Ave\\nLongmont, CO 80501...</td>\n",
       "      <td>rini twait e th ave longmont co rtwait graphic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Message-ID  \\\n",
       "0   <8345058.1075840404046.JavaMail.evans@thyme>   \n",
       "1   <1512159.1075863666797.JavaMail.evans@thyme>   \n",
       "2  <26118676.1075862176383.JavaMail.evans@thyme>   \n",
       "3  <10369289.1075860831062.JavaMail.evans@thyme>   \n",
       "4  <26728895.1075860815046.JavaMail.evans@thyme>   \n",
       "\n",
       "                              From                               To  \\\n",
       "0  ('advdfeedback@investools.com')  ('advdfeedback@investools.com')   \n",
       "1    ('richard.sanders@enron.com')    ('richard.sanders@enron.com')   \n",
       "2            ('m..love@enron.com')            ('m..love@enron.com')   \n",
       "3     ('leslie.milosevich@kp.org')     ('leslie.milosevich@kp.org')   \n",
       "4     ('rtwait@graphicaljazz.com')     ('rtwait@graphicaljazz.com')   \n",
       "\n",
       "                  Date                                            content  \\\n",
       "0  2002-01-29 23:20:55  INVESTools Advisory\\nA Free Digest of Trusted ...   \n",
       "1  2000-09-20 19:07:00  ----- Forwarded by Richard B Sanders/HOU/ECT o...   \n",
       "2  2001-10-30 16:15:17  hey you are not wearing your target purple shi...   \n",
       "3  2002-01-30 17:54:18  Leslie Milosevich\\n1042 Santa Clara Avenue\\nAl...   \n",
       "4  2002-01-30 19:36:01  Rini Twait\\n1010 E 5th Ave\\nLongmont, CO 80501...   \n",
       "\n",
       "                                       clean_content  \n",
       "0  investools advisory free digest trusted invest...  \n",
       "1  forwarded richard b sanders hou ect pm justin ...  \n",
       "2  hey wearing target purple shirt today mine wan...  \n",
       "3  leslie milosevich santa clara avenue alameda c...  \n",
       "4  rini twait e th ave longmont co rtwait graphic...  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word search with dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's find all emails that mention specific words, such as \"sell enron stock\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       Message-ID                        From  \\\n",
      "154  <6336501.1075841154311.JavaMail.evans@thyme>  ('sarah.palmer@enron.com')   \n",
      "\n",
      "                             To                 Date  \\\n",
      "154  ('sarah.palmer@enron.com')  2002-02-01 14:53:35   \n",
      "\n",
      "                                               content  \\\n",
      "154  \\nJoint Venture: A 1997 Enron Meeting Belies O...   \n",
      "\n",
      "                                         clean_content  \n",
      "154  joint venture enron meeting belies officers cl...  \n"
     ]
    }
   ],
   "source": [
    "mask = df.clean_content.str.contains('sell enron stock', na =False)  #na=False to ingnore all rows containing missing values\n",
    "print(df[mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 6)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df[mask]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using list of terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchList = ['enron stock', 'sell stock', 'stock bonus', 'sell enron stock']\n",
    "\n",
    "filtered_mails = df.loc[df['clean_content'].str.contains('|'.join(searchList), na =False)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(314, 6)\n"
     ]
    }
   ],
   "source": [
    "print(filtered_mails.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create a flag from this which you can use as a feature in a machine learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['flag'] =  np.where((df.clean_content.str.contains('|'.join(searchList))==True),1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1776\n",
       "1     314\n",
       "Name: flag, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['flag'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have now managed to search for a list of strings in several lines of text data. <br>\n",
    "These skills come in handy when you want to flag certain words based on what you discovered in your topic model, or when you know beforehand what you want to search for. In the next cells you're going to learn how to clean text data and to create your own topic model to further look for indications of fraud in your text data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Text Data:\n",
    "1. `Tokenization`: split the text-sentences, sentences-Words, remove Punctuations(strings into list of Substrings)\n",
    "2. Remove `stopwords`\n",
    "3. Lemmatize words: `Passive-Active` and `(Past,Future) - Present`\n",
    "4. stem the words :  reduce them to their `root` Form\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define stopwords to exclude\n",
    "stop = set(stopwords.words())\n",
    "stop.update((\"to\",\"cc\",\"subject\",\"http\",\"from\",\"sent\", \"ect\", \"u\", \"fwd\", \"www\", \"com\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define punctuations to exclude and lemmatizer\n",
    "exclude = set(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lemma =  WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean(text, stop):\n",
    "    text = text.rstrip()\n",
    "    # Remove stopwords\n",
    "    stop_free = ' '.join([word for word in text.lower().split() if ((  word not in stop) and not(word.isdigit())) ])\n",
    "    \n",
    "    # Remove punctuations\n",
    "    punc_free = ''.join(word for word in stop_free if  (word not in exclude))\n",
    "    \n",
    "    normalized = ' '.join(lemma.lemmatize(word) for word in punc_free.split())\n",
    "    return normalized\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'investools advisory free digest trusted investment advice unsubscribe free newsletter please see issue fried sell stock gain month km rowe january index confirms bull market aloy small cap advisor earns lbix compounding return pine tree pcl undervalued high yield bank put customer first aso word sponsor top wall street watcher zacks year year gain moving best brightest wall street big money machine earned zacks five year average annual gain start outperforming long term get zacks latest stock buylist free day trial investools go zaks mtxtu zakstb investools advisory john brobst investools fried sell stock lock month km david fried know stock undervalued company management buy back share open market latest triumph pocketing impressive gain three short month selling four buyback stock include gain auto retailer automation incorporated gain digital phone system purveyor inter tel intl fried recent move buy kmart corporation km beleaguered discount retailer declared bankruptcy think k mart go business fried say take recovery possibility bought share another fried pick cor net corporation ccbl provides range technology service broadband network today telecom spending slowdown hit company hard net sale fell million last quarter caused net loss million v million gain last year fried cite buyback plan million restructuring charge proof management see rosier future david fried advice see buyback index portfolio january buyback letter david fried provides wealth building opportunity company repurchasing stock free day trial go investools go back mtxtu back rowe january index confirms bull market aloy rowe say january index confirms see bull market first five trading day provided gain nasdaq p dow industrials rowe say five day index correctly predicted market direction year since four exception include three year fed fund rate doubled year rowe maintains sure recommendation seven company say leading market one alloy incorporated aloy medium company direct marketer provides content community commerce generation roughly million people year age rowe like market account billion disposable income grow faster overall population q saw earnings increase sale another rowe pick new century financial corporation ncen financier make buy sell service prime mortgage loan secured first mortgage single family home borrower typically plenty equity property secure loan suffer weak credit profile high debt income ratio q earnings grew hike sale rowe advice see investment opportunity february wall street digest momentum investor donald rowe target stock mutual fund capable generating annual return free day trial go investools go wall mtxtu wall small cap advisor earns lbix major index suffered terrible year richard geist recommendation earned healthy list many reason selection see growth going forward include extremely bullish monetary condition high productivity inflation sight yield curve continues steepen investor sentiment poll becoming bearish always contrary indicator say geist latest recommendation buy share leading brand lbix company canada largest independent food brand management company expanding u geist particularly like firm save money integrated distribution system system make product raw material provides packaging warehousing distribution recent financial result show leading brand roll fy saw revenue grow million net income million share last year loss geist predicts company see revenue reach million million yield forward think lbix significantly undervalued geist say range leading brand strong buy richard geist advice see highlighted stock february richard geist strategic investing richard geist integrates psychological aspect investing methodology selecting small company stock free day trial go investools go stin mtxtu stin compounding return pine tree pcl growing tree usually noisy business catch attention investment medium good business say dick young timber business le volatile capital intensive manufacturing young see demand timber increasing population increase note average return timber investment outperformed p average annual return young favorite timber play plum creek timber pcl one largest private timberland owner u reit primary goal profit acquiring managing land young say plum creek timber yield status reit make ideal tax deferred account another young timber selection deltic timber corporation company grows harvest timber acre arkansas louisiana main company goal expand timber holding sustainable harvest level young say share good portfolio counterweight value investor appreciate intrinsic worth underlying real natural resource dick young advice see investment commentary february richard young intelligence report richard young us buy hold strategy mentor warren buffett uncover low risk high reward opportunity free day trial go investools go mtxtu undervalued high yield bank put customer first aso amsouth bancorp aso giving investor healthy yield risk involved say jodie wei investment quality trend billion asset amsouth one largest financial institution south office credit bank success putting customer first wei like amsouth us new technology save money streamlining operation note amsouth ranked number six eweek fast track list company deploy cutting edge technology throughout operation number merrill lynch financial service firm placed higher amsouth internet banking group quadrupled customer base last year wei say aso share undervalued stock selling near yield wei see upside potential dividend risen annually past year buyback plan million share authorized september stock reasonable x priced yield aso undervalued buy considered wei say jodie wei advice see investment spotlight january income digest digest excerpt investment publication highlight weather income oriented opportunity uncovered top mind wall street free day trial go investools go mtxtu word sponsor new report top pick despite slumping economy shaky stock market frank curzio bull eye pick gained whopping curzio selected stock incredible potential get red hot pick today click investools go fxcp fxcp mtxtu disclaimer investools advisory published solely informational purpose solicit offer buy sell stock mutual fund security attempt claim complete description security market development referred material expression opinion change without notice information obtained internal external source investools considers reliable investools independently verified information investools guarantee accurate complete investools undertake advise anyone investools employee officer director may time time position security mentioned may sell buy security remove free email list removed email distribution list free investools advisory update simply click link hit send email launched copy paste email address new outgoing email message hit send email launched mailto bonnie investools important automated system cancel paid newsletter service subscription investools tried unsubscribing past believe received message error please send email mailto itfeedback investools voice concern removed list paid subscription information question investools service paid subscription contact investools customer service center investools cgi help pl info pr faq html'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text = []\n",
    "clean(df['clean_content'][0],stop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'rstrip'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-2b2c7b1f1b87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clean_content'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0mclean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-75-fb1eacb7be71>\u001b[0m in \u001b[0;36mclean\u001b[0;34m(text, stop)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mclean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Remove stopwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mstop_free\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0mword\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdigit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'rstrip'"
     ]
    }
   ],
   "source": [
    "for text in df['clean_content']:\n",
    "    (clean(text,stop))\n",
    "\n",
    "print(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "354"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import nltk\n",
    "# nltk.download('wordnet')\n",
    "len(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gensim\n",
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dictionary and corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(15445 unique tokens: ['account', 'accurate', 'acquiring', 'acre', 'address']...)\n"
     ]
    }
   ],
   "source": [
    "# Import the packages\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "\n",
    "# Define the dictionary\n",
    "dictionary = corpora.Dictionary(clean_text)\n",
    "\n",
    "# Define the corpus \n",
    "corpus = [dictionary.doc2bow(text) for text in clean_text]\n",
    "\n",
    "# Print corpus and dictionary\n",
    "print(dictionary)\n",
    "#print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LDA model\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics=5, id2word=dictionary, passes=5)\n",
    "\n",
    "# Save the topics and top 5 words\n",
    "topics = ldamodel.print_topics(num_words = 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.014*\"enron\" + 0.010*\"company\" + 0.006*\"gas\" + 0.005*\"energy\" + 0.005*\"new\"')\n",
      "(1, '0.025*\"enron\" + 0.011*\"company\" + 0.006*\"stock\" + 0.005*\"power\" + 0.005*\"message\"')\n",
      "(2, '0.032*\"enron\" + 0.013*\"company\" + 0.013*\"said\" + 0.008*\"mr\" + 0.005*\"stock\"')\n",
      "(3, '0.050*\"enron\" + 0.030*\"employee\" + 0.025*\"company\" + 0.024*\"million\" + 0.019*\"energy\"')\n",
      "(4, '0.025*\"enron\" + 0.019*\"stock\" + 0.012*\"option\" + 0.011*\"company\" + 0.009*\"dynegy\"')\n"
     ]
    }
   ],
   "source": [
    "# Print the results\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
